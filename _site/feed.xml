<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/enro/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/enro/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-08-15T11:50:16+02:00</updated><id>http://localhost:4000/enro/feed.xml</id><title type="html">Kalaiselvan Thangaraj</title><author><name>Kalaiselvan Thangaraj</name><email>kalaiselvan.thangarajs@gmail.com</email></author><entry><title type="html">Automatic Formal Specification Generation And Verification</title><link href="http://localhost:4000/enro/projects/2024-07-17-automatic-verification/" rel="alternate" type="text/html" title="Automatic Formal Specification Generation And Verification" /><published>2024-07-17T00:00:00+02:00</published><updated>2024-08-12T15:12:54+02:00</updated><id>http://localhost:4000/enro/projects/automatic-verification</id><content type="html" xml:base="http://localhost:4000/enro/projects/2024-07-17-automatic-verification/"><![CDATA[<ul class="large-only" id="markdown-toc">
  <li><a href="#background-and-problems" id="markdown-toc-background-and-problems">Background and problems</a></li>
  <li><a href="#goal" id="markdown-toc-goal">Goal</a></li>
</ul>

<!-- Intro paragraph, what is this blog about? -->
<p>Let me start by asking you this question. Do you know if the neural network you developed work as you intended? You might have used a verification dataset to check if your model has generalized well to unseen data. But is that enough to know if the neural network’s functionality is correct and complete? What if the network is going to be deployed in a safety ctitical system like autonomous cars? Will the usual verification dataset be enough to guarantee the functionalities? It is absolutely necessary to make sure that the software present in autonomous vehicles have no functional faults for the safety of the passengers in it.</p>

<h2 id="background-and-problems">Background and problems</h2>
<!-- Safety standards and the v-model -->
<p>Automotive industry is very well regulated by both the government and industry consortiums, to make sure safety is a priority when manufacturing vehicles. Best practices in the industry are captured in the form of safety standards. One of the most well-known safety standard is the <a href="https://www.iso.org/standard/68383.html">ISO 26262</a> which deals with the functional safety of the E/E systems of the car, including both hardware and software. It covers the overall product development lifecycle from specification, design, implementation, integration, verificationa, validation and product release. The standard follows the V-model of systems engineering process. One of the core concepts anchoring the v-model is verification and validation.</p>

<figure class="image">
    <img src="../../assets/img/blog/v-model.jpeg" alt="V-model of systems engineering process" />
    <figcaption>V-model of systems engineering process</figcaption>
  </figure>

<!-- Verification and validation, problems in AI V&V -->
<p>Verification is the process of checking if our system is built in accordance with the given requirement and specifications. Validation is the process of checking if the specified requirements meet the needs of the intended task or the customer. In other words, verification is answering the question, “Are we building the product right?” and validation answers the question “Are we building the right product?”. Verification and Validation (V&amp;V) plays an important role in assessing safety and building trust in a system. Currently available methods for V&amp;V fall short when it comes to software systems with AI in it. And the contribution of AI in cars are constantly increasing from smart climate control to powering the autonomous driving functionality.</p>

<!-- Problems -->
<p>About 90% of all road accidents are attributed to human error and automating the driving task itself can save many lifes. The task of replacing the driver with an automated system is not easy. Automakers need to be sure themselves and prove it to their customers that they can trust the vehicle with their lives. Current industry practice in testing the functionality of the vehicle is conduct extensive testing in simulations and in real world. The problem with this approach is that this approach is very resource intensive. According to this <a href="https://www.rand.org/content/dam/rand/pubs/research_reports/RR1400/RR1478/RAND_RR1478.pdf">research</a> it would take hundreds of millions of miles and sometimes hundreds of billions of miles for a autonomous vehicle to demonstrate their performance in terms of fatalities and injuries. How long would it take to complete all these miles before a self-driving technology can hit the roads. As it stands, about 90% of the self-driving problem is already solved but we can’t guarantee that it will be safe in all driving conditions. Developers of these technologies make sure to collect diverse data and train their system on it to make sure they perform equally well in all situations.</p>

<p>We need better methods that can complement simulation-based and real-world testing. Formal methods seems to be promising in that area with their ability to provide us with mathematical proofs which can eliminate the need for extensive testing. As most of the researchers are concentrating in developing the technology that makes the cars drive themselves, I decided to work on methods to verify if they are safe for my masters thesis. Perception is usually the bottleneck for autonomous driving technology, as it affects all other systems in a chain reaction. Several works in verifying the perception systems exist and they mostly focus on verifing if the perception system is robust to input changes. Very little works exist in trying to verifying the functionality of the perception systems. For example, did an object detection module classify an object as a car based on the right reasons? Did it learn to recognize a car correctly? These are some of the questions we would be interested in verifying.</p>

<h2 id="goal">Goal</h2>
<p>On investigating why verification is hard for AI-based systems, the following problems were found.</p>

<p><strong>1. AI is a blackbox</strong> <br />
Neural networks are often used in perception systems for object detection and tracking. They are opaque systems, meaning their decision making process is not seen. This makes functional verification difficult. Explainable AI, a whole new field has emerged to develop AI systems that are explainable, which would make the verification process much easier.</p>

<p><strong>2. Validatity of verification</strong> <br />
As mentioned earlier, AI systems are usually verified using simulation-based testing and real-world testing. But the validity of those verification becomes obsolete when the model is updated. All the situations that was driven in simulations and in real-world needs to be driven again to make sure the system performs well after the changes. We would need automation tools that will automatically verify and validate these systems when updated. Such automatic tools in combination with formal methods based verification can verify the systems effectively and much faster. Today, there are not many tools that are capable of continuous verification.</p>

<p><strong>3. Lack of formal specifications</strong> <br />
Verification is the process of checking if our system is built in accordance with the given requirements and specifications. For it to be effective, we need to set correct set of requirements for the system. For effective formal verification, the specifications used to verify also needs to be specified formally. They are called as formal specifications. Now the problem is, how will we formally specify the expected behaviour of a perception system. For example, let’s say our system needs to correctly identify and classify all pedestrians on the road. How will we specify this requirement formally?</p>

<p>The goal of this thesis is to contribute towards solving all of these issues in such a way that the autonomous vehicles homologation process is improved. To that end, a framework was created that will continuously verify neural network based object detection modules. The framework takes in an ontology of the world in which the model is going to be deployed. Eg: An ontology that models all the objects that a car might encounter in its driving environments. The framework parses the ontology and creates syntactically and semantically correct formal specifications in a language called Conspec. For verification, the framework uses a VLM (CLIP) to verify if the model satisfies the generated Conspec specifications.</p>

<p>You can read more about my thesis here <br /></p>

<p><a href="/enro/assets/files/thangaraj_kalaiselvan_thesis.pdf">thesis.pdf</a></p>

<p><br />
<br /></p>

<!-- 
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://ks-disqus-com.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
 -->]]></content><author><name>Kalaiselvan Thangaraj</name><email>kalaiselvan.thangarajs@gmail.com</email></author><category term="projects" /><summary type="html"><![CDATA[Master thesis project for the degree program M.Sc Autonomous Systems in colloboration with ThoughtWorks]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/enro/assets/img/blog/automatic-verification-home.jpg" /><media:content medium="image" url="http://localhost:4000/enro/assets/img/blog/automatic-verification-home.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Distributed State Estimation Using Kalman-Consensus Filter</title><link href="http://localhost:4000/enro/projects/2024-05-10-distributed-state-estimation/" rel="alternate" type="text/html" title="Distributed State Estimation Using Kalman-Consensus Filter" /><published>2024-05-10T00:00:00+02:00</published><updated>2024-08-15T02:46:17+02:00</updated><id>http://localhost:4000/enro/projects/distributed-state-estimation</id><content type="html" xml:base="http://localhost:4000/enro/projects/2024-05-10-distributed-state-estimation/"><![CDATA[<ul class="large-only" id="markdown-toc">
  <li><a href="#background" id="markdown-toc-background">Background</a></li>
  <li><a href="#goal-and-project-setup" id="markdown-toc-goal-and-project-setup">Goal and project setup</a></li>
  <li><a href="#the-algorithm" id="markdown-toc-the-algorithm">The algorithm</a></li>
  <li><a href="#results" id="markdown-toc-results">Results</a></li>
</ul>

<p>Distributed systems is the concept of connecting different computing systems together. In robotics, this concept is popularly known as swarm robotics. State estimation is an important process that is used to estimate a state of a system, a robot’s position for instance, when we have uncertain sensor measurements. Estimating state of robotic systems that work as a team may be crucial for many tasks. We must have an effective method for any individual robotic system to be aware of its own position and of others at all times. In order to do this, we have to use Distributed State Estimation (DSE) techniques.</p>

<h2 id="background">Background</h2>
<p>Before jumping to use any DSE techniques, let us first understand some of the limitations of using traditional state estimation techniques for distributed systems. We have to consider two important factors considering distributed nature of the systems. Computation - How are we going to use the sensor measurements to estimate the state of all the system?. Communication - How are we going to communicate the estimated information to all the systems? We have the following choices.</p>

<p>We can have a centralized system which collects the sensor measurements from all the systems and estimates their state and communicates it back to them. This is the conventional centralized approach. The advantages of this method is the computation is performed by a powerful centralized system and the disadvantage is the communication load the system has to handle when collecting data and sending them back. It grows linearly as the number of robotic systems connected to the network. Otherwise, we could eliminate centralized systems and let the individual systems collect sensor measurements from all other systems and estimate the information for themselves. This method eases up the communication load but in turn increases their computational load.</p>

<p>This is where the distributed systems come in. The idea is to limit the communication of each system to only its neighbours. This reduces the amount of data we need to collect and process and is also easy on the computational load. But is it enough if we only use data from neighbouring systems to estimate the state? Turns out that we get fairly accurate estimations as compared to the centralized estimation techniques. Distributed methods leverage the connected nature of these systems and uses it to have an averaging effect on all the individual estimations.</p>

<figure class="image">
    <img src="../../assets/img/blog/distributed-comparison.jpg" alt="Comparison of different estimation methods" />
    <figcaption>Comparison of different estimation methods</figcaption>
  </figure>

<h2 id="goal-and-project-setup">Goal and project setup</h2>

<p>Surveillance in facilities having a huge area is very important for maintaining security. Identifying an object of interest and tracking it around the area is a difficult task for many reasons. One reason is that a single sensor doesn’t have enough range to cover the entire space of the environement. So, we have to rely on multiple sensors to get the job done. For a successful object tracking application, we may use distributed state estimation techniques, where all the sensors in an environment (say camera) can track objects across with more accuracy. Kalman-consensus filter is a modification of the original kalman filter algorithm to accomodate distributed systems. The goal of this project is to track an object through huge space, using the Kalman-consensus filter. We assume that the environment is sufficiently equipped with multiple sensors for our needs.</p>

<p>We simulate an environment equipped with 12 sensors as shown in the figure below. To make things more interesting, we can divide these sensors into two groups, corner sensors and edge sensors. Let us assume that the corner sensors are more accurate than the edge sensors and have long range. We can also have different mesurement models for the sensors i.e. let us assume that a set of edge sensors may only sense the movement of the target in x-axis and the set its motion in y-axis. Let the corner sensors be able to detect full range of motion of the target.</p>

<figure class="image">
    <img src="../../assets/img/blog/distributed-project-setup.jpg" alt="Figure depicting the environment where we are going to track an object" />
    <figcaption>Figure depicting the environment where we are going to track an object</figcaption>
  </figure>

<h2 id="the-algorithm">The algorithm</h2>

<p>The Kalman-consensus filter works similar to the conventional Kalman filter. The algorithm consists of 5 steps as seen in the figure</p>

<dl>
    <dt>1. Initialize state estimate variables and their covariance</dt>
    <dd>We start with a random estimate for the state of the object being tracked. We can use the sensor measurements for this.</dd>
    <dt>2. Locally aggregate sensor measurements and the covariance matrices (uncertainities)</dt>
    <dd>We collect the sensor measurements from the neighbouring nodes</dd>
    <dt>3. Calculate an intermediate estimate of the state</dt>
    <dd>We use the aggregated data and the data from the node itself to calculate an intermediate estimate of the state</dd>
    <dt>4. Get consensus on the estimates </dt>
    <dd>We use the epsilon term to choose how much the estimates of the neighbouring nodes affect ours. We can choose this value based on the accuracy of the neighbouring sensors </dd>
    <dt>5. Update and prediction step </dt>
    <dd> We update the current values of the state estimate with the new one and repeat</dd>
</dl>
<p><br /></p>
<figure class="image">
    <img src="../../assets/img/blog/dkf-algorithm.jpg" alt="Figure depicting the environment where we are going to track an object" />
    <figcaption>Figure depicting the environment where we are going to track an object</figcaption>
  </figure>

<h2 id="results">Results</h2>
<p>An elliptical trajectory with random noise is taken as our true trajectory. We would like to investigate the following things</p>

<ol>
  <li>Can the Kalman-consensus filter track the object well in a distributed setting?</li>
  <li>What are the effect of sensors with different accuracy in the network?</li>
  <li>What is the effect of having different measurement models for the two group of sensors?</li>
</ol>

<p>The results of the use of Kalman-consensus filter are shown below. In the first image, we can see the sensor measurements of all 12 sensors and the estimates they came up with. The algorithm is able to track the object well even with high sensor noise. In the second image, all the edge sensors have low accuracy than the corner sensors. The result shows that even with a sensor network having differnt accuracy and robustness the algorithm is able to track the object well. In the final image, we see the estimates of the sensors when the two group of sensors have different measurement models. It can be seen that different measurement models affects the scale of the estimates and also skews them towards a side. The estimates of the corner sensors are better than the others even though its neighbours are negatively contributing in calculating the estimate. The results with different measurement models may improve if the number of sensors in the network increases.</p>

<p><br /></p>

<figure class="image">
    <img src="../../assets/img/blog/distributed-result-1.png" alt="Image showing the sensor measurements and the estimates calculated using the Kalman-consensus filter for all 12 sensors" />
    <figcaption>Image showing the sensor measurements and the estimates calculated using the Kalman-consensus filter for all 12 sensors</figcaption>
  </figure>

<p><br /></p>

<figure class="image">
    <img src="../../assets/img/blog/distributed-result-2.png" alt="Image showing the sensor measurements and the estimates for different sensor accuracies for corner and edge sensors" />
    <figcaption>Image showing the sensor measurements and the estimates for different sensor accuracies for corner and edge sensors</figcaption>
  </figure>

<p><br /></p>

<figure class="image">
    <img src="../../assets/img/blog/distributed-result-3.png" alt="Image showing the sensor measurements and the estimates for different measurement models for corner and edge sensors" />
    <figcaption>Image showing the sensor measurements and the estimates for different measurement models for corner and edge sensors</figcaption>
  </figure>

<p>You can find the MATLAB code for this project here on <a href="https://github.com/kalaiselvan-t/Kalman-Consensus-Filter">Github</a></p>]]></content><author><name>Kalaiselvan Thangaraj</name><email>kalaiselvan.thangarajs@gmail.com</email></author><category term="projects" /><summary type="html"><![CDATA[Project for the course Intelligent Distributed Systems at University of Trento]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/enro/assets/img/blog/IDP.jpg" /><media:content medium="image" url="http://localhost:4000/enro/assets/img/blog/IDP.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>